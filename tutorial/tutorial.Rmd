---
title: "vera4cast tutoral"
author: Freya Olsson
output:
  md_document: 
    variant: markdown_github
    number_sections: true
    toc: true
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# This VERA tutorial:

This document presents a short tutorial to get you started generating ecological forecasts, specifically for submission to the Virginia Ecoforecast Reservoir Analysis (VERA) Forecast Challenge. The materials are modified from those initially developed for the EFI-NEON Forecast Challenge (found [here](https://zenodo.org/records/8316966)). To learn more about the VERA Forecast Challenge (see our [website](https://www.ltreb-reservoirs.org/vera4cast/)).

The development of these materials has been supported by NSF grants DEB-2327030, DEB-1926388, and DBI-1933016.

To complete the tutorial via this markdown document, the following R packages will need to be installed first:

-   `remotes`
-   `tidyverse`
-   `lubridate`
-   `vera4castHelpers` (from Github)

The following code chunk should be run to install packages.

```{r eval = F}
install.packages('remotes')
install.packages('tidyverse') # collection of R packages for data manipulation, analysis, and visualisation
install.packages('lubridate') # working with dates and times
install.packages('here')

remotes::install_github('LTREB-reservoirs/vera4castHelpers') # package to assist with forecast submission
```

```{r warning=FALSE}
library(tidyverse)
library(lubridate)
library(ggplot2); theme_set(theme_bw())
library(vera4castHelpers)
```

If you do not wish to run the code yourself, you can alternatively follow along via the markdown document (tutorial.md).

# Introduction to VERA Forecast Challenge

The VERA Forecast Challenge is hosted by the Center for Ecosystem Forecasting at Virginia Tech [CEF](https://ecoforecast.centers.vt.edu). We are using forecasts to compare the predictability of different ecosystem variables, across many different ecosystem conditions, to identify the fundamental predictability of freshwater ecosystems.

The VERA Forecast Challenge is one component of the Virginia Reservoirs LTREB project, which is both monitoring and forecasting two reservoirs with contrasting dissolved oxygen conditions in southwestern Virginia, USA to broadly advance our understanding of freshwater ecosystem predictability.

## The Challenge

**What**: Freshwater water quality.

**Where**: Two Virginia reservoirs (managed by the Western Virginia Water Authority) and the stream that connects them. To learn more about these freshwater ecosystems, see [here](https://www.ltreb-reservoirs.org/reservoirs/).

**When**: Daily forecasts for at least 30 days-ahead in the future. New forecast submissions that are continuously updated with observations as soon as they become available are accepted daily. The only requirement is that submissions are predictions of the future at the time the forecast is submitted.

For the VERA Challenge, you can chose to submit to any combination of sites and variables using any method. Find more information about the targets available [here](https://www.ltreb-reservoirs.org/vera4cast/targets.html).

## Submission requirements

For the VERA Challenge, submitted forecasts must include *quantified uncertainty*. The submitted file can represent uncertainty using an ensemble forecast (multiple realizations of future conditions) or a distribution forecast (defined by different parameters depending on the distribution), specified in the family and parameter columns of the forecast file.

### File format

The file is a csv format with the following columns:

-   `project_id`: use `vera4cast`.

-   `model_id`: the short name of the model defined as the `model_id` in the file name (see below) and in your registration. The `model_id` should have no spaces.

-   `datetime`: forecast timestamp. Format `%Y-%m-%d %H:%M:%S`.

-   `reference_datetime`: the start of the forecast (0 times steps into the future). There should only be one value of reference_datetime in the file. Format is `%Y-%m-%d %H:%M:%S`.

-   `duration`: the time-step of the forecast. Use the value of P1D for a daily forecast and PT1H for an hourly forecast.

-   `site_id`: code for site.

-   `depth_m`: the depth (meters) for the forecasted variable.

-   `family`: name of the probability distribution that is described by the parameter values in the parameter column. For an ensemble forecast, the `family` column uses the word `ensemble` to designate that it is a ensemble forecast and the parameter column is the ensemble member number (1, 2, 3 ...). For a distribution forecast, the `family` describes the type of distribution. For a parametric forecast with a normal distribution, the `family` column uses the word `normal` to designate a normal distribution and the parameter column must have values of `mu` and `sigma` for each forecasted variable, site_id, depth and time combination.

Parametric forecasts for binary variables should use bernoulli as the distribution.

The following names and parameterization of the distribution are supported (family: parameters):

-   lognormal: mu, sigma
-   normal: mu,sigma
-   bernoulli: prob
-   beta: shape1, shape2
-   uniform: min, max
-   gamma: shape, rate
-   logistic: location, scale
-   exponential: rate
-   poisson: lambda

If you are submitting a forecast that is not in the supported list above, we recommend using the ensemble format and sampling from your distribution to generate a set of ensemble members that represents your distribution. The full list of required columns and format can be found in the [Challenge documentation](https://www.ltreb-reservoirs.org/vera4cast/instructions.html#forecast-file-format).

-   `parameter` the parameters for the distribution or the number of the ensemble members.

-   `variable`: standardized variable name.

-   `prediction`: forecasted value.

# The forecasting workflow

## Read in the data

We start forecasting by first looking at the historicalal data - called the *targets*. These data are available in near real-time, with the latency of approximately 24-48 hrs. Here is how you read in the data from the targets file available:

```{r eval=TRUE, echo = TRUE, error=FALSE, warning=FALSE, message=FALSE}
#read in the targets data
targets <- read_csv('https://renc.osn.xsede.org/bio230121-bucket01/vera4cast/targets/project_id=vera4cast/duration=P1D/daily-insitu-targets.csv.gz')
```

Information on the VERA sites can be found in the `vera4cast_field_site_metadata.csv` file on GitHub. This table has information about the field sites, including location, reservoir depth, and surface area.

```{r eval=TRUE, echo = TRUE, error=FALSE, warning=FALSE, message=FALSE}
# read in the sites data
site_list <- read_csv("https://raw.githubusercontent.com/LTREB-reservoirs/vera4cast/main/vera4cast_field_site_metadata.csv",
                      show_col_types = FALSE)
```

Let's take a look at the targets data!

```{r eval = T, echo = F}
glimpse(targets)

```

The columns of the targets file show the time step (duration, P1D), the 4 character site code (`site_id`), the variable being measured, and the mean daily observation. We will start by just looking at Falling Creek Reservoir (`fcre`).

```{r}
site_list <- site_list %>%
  filter(site_id == 'fcre')

targets <- targets %>%
  filter(site_id == 'fcre')

targets |> distinct(variable) |> pull()
```

There are a number of different physical, chemical, and biological variables with observations at fcre. We will start by just looking at P1D Temp_C_mean (mean daily water temperatures).

```{r}
targets <- targets %>%
  filter(variable == 'Temp_C_mean',
         duration == 'P1D')
```

## Visualize the data

```{r targets, eval = T, echo = F, warning=FALSE, fig.dim=c(10,10), fig.cap='Figure: Temperature targets data at FCR'}
targets %>%
  filter(variable == 'Temp_C_mean') %>%
  ggplot(., aes(x = datetime, y = observation)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  facet_wrap(~depth_m) +
  labs(title = 'water temperature')

```

We can think about what type of models might be useful to predict water temperature. Below are descriptions of three simple models to get you started forecasting:

-   We could use information about current conditions to predict the next day. What is happening today is usually a good predictor of what will happen tomorrow (persistence model).
-   We could also think about what the historical data tells us about reservoir dynamics this time of year. For example, conditions in January this year are likely to be similar to January last year (climatology/day-of-year model)
-   We could also look at the lake variables' relationship(s) with other variables. For example, we could use existing forecasts about the weather to generate forecasts about the reservoir variables.

To start, we will produce forecasts for just one of these depths - the focal depth at fcre, 1.6 m.

```{r}
targets <- targets %>%
  filter(depth_m == 1.6)
```

# Introducing co-variates

One important step to overcome when thinking about generating forecasts is to include co-variates in the model. A water temperature forecast, for example, may be benefit from information about past and future weather. The `vera4castHelpers` package includes functions for downloading past and future NOAA weather forecasts for the VERA sites. The 3 types of data are as follows:

-   stage_1: raw forecasts - 31 member ensemble forecasts at 3 hr intervals for the first 10 days, and 6 hr intervals for up to 35 days at the NEON sites.
-   stage_2: a processed version of Stage 1 in which fluxes are standardized to per second rates, fluxes and states are interpolated to 1 hour intervals and variables are renamed to match conventions. We recommend this for obtaining future weather. Future weather forecasts include a 30-member ensemble of equally likely future weather conditions.
-   stage_3: can be viewed as the "historical" weather and is combination of day 1 weather forecasts (i.e., when the forecasts are most accurate).

This code create a connection to the dataset hosted remotely at an S3 storage location. To download the data you have to tell the function to `collect()` it. These data set can be subsetted and filtered using `dplyr` functions prior to download to limit the memory usage.

## Download co-variates

### Download historical weather forecasts

We will generate a water temperature forecast using `air_temperature` as a co-variate. The following code chunk connects to the remote location, filters the dataset to the sites and variables of interest and then collects into our local environment.

```{r, message=FALSE}
# past stacked weather
historical_weather_s3 <- vera4castHelpers::noaa_stage3()

variables <- c("air_temperature")

historical_weather <- historical_weather_s3  |> 
  dplyr::filter(site_id %in% site_list$site_id,
                variable %in% variables) |> 
  dplyr::collect()

historical_weather

```

This is an hourly stacked ensemble of the one day ahead forecasts. We can take a mean of these ensembles to get an estimate of mean daily historical conditions. For the historical data we do not need the individual ensemble members, and will train with the ensemble mean.

```{r}
# aggregate the past to mean values
historical_weather <- historical_weather |> 
  mutate(datetime = as_date(datetime)) |> 
  group_by(datetime, site_id, variable) |> 
  summarize(prediction = mean(prediction, na.rm = TRUE), .groups = "drop") 

historical_weather
```

### Download future weather forecasts

We can then look at the future weather forecasts in the same way but using the `noaa_stage2()`. The forecast becomes available from NOAA at 5am UTC the following day, so we need to use the air temperature forecast from yesterday (`noaa_date`) to make our real-time water quality forecasts.

```{r, message=FALSE}
forecast_date <- Sys.Date() 
noaa_date <- forecast_date - days(1)

future_weather_s3 <- vera4castHelpers::noaa_stage2(start_date = as.character(noaa_date))

future_weather <- future_weather_s3 |> 
  dplyr::filter(datetime >= forecast_date,
                site_id %in% site_list$site_id,
                variable %in% variables) |> 
  collect()

future_weather
```

We can use the individual ensemble member in our model to include driver uncertainty in the water temperature forecast. To generate a daily water temperature forecast, we will use a daily water temperature to train and run our model. This is calculated from the hourly data we have but retains the ensemble members as a source of driver uncertainty.

```{r}
# aggregate the past to mean values
future_weather <- future_weather |> 
  mutate(datetime = as_date(datetime)) |> 
  group_by(datetime, site_id, variable, parameter) |> # parameter is included in the grouping variables
  summarize(prediction = mean(prediction, na.rm = TRUE), .groups = "drop") 
```

```{r weather-data}
ggplot(future_weather, aes(x=datetime, y=prediction)) +
  geom_line(aes(group = parameter), alpha = 0.4)+
  geom_line(data = historical_weather) +
  facet_wrap(~variable, scales = 'free') +
  coord_cartesian(xlim = c(forecast_date - 150, forecast_date + 30))
```

We have separate `historical_weather` for training/calibration and `future_weather` to generate a forecast. Finally, we will also convert to Celsius from Kelvin.

```{r}

historical_weather <- historical_weather |> 
  pivot_wider(names_from = variable, values_from = prediction) |>
  mutate(air_temperature = air_temperature - 273.15) # convert to degree C


future_weather <- future_weather |>
  pivot_wider(names_from = variable, values_from = prediction) |>
  mutate(air_temperature = air_temperature - 273.15) # convert to degree C

```

# Linear model with co-variates

We will fit a simple linear model between historical air temperature and the water temperature targets data. Using this model we can then use our future forecasts of air temperature (all 31 ensembles from NOAA GEFS) to estimate water temperature. The ensemble weather forecast will therefore propagate uncertainty into the water temperature forecast and give an estimate of driver data uncertainty.

We will start by joining the historical weather data with the targets to aid in fitting the linear model.

```{r}
targets_lm <- targets |> 
  pivot_wider(names_from = 'variable', values_from = 'observation') |> 
  left_join(historical_weather, 
            by = c("datetime","site_id"))

tail(targets_lm)
```

To fit the linear model, we use the base R `lm()` but there are also methods to fit linear (and non-linear) models in the `fable::` package. You can explore the [documentation](https://otexts.com/fpp3/regression.html) for more information on the `fable::TSLM()` function.

```{r}
# set up forecast df
forecast_df <- NULL
forecast_horizon <- 30 # make a 30 day-ahead forecast
forecast_dates <- seq(from = ymd(forecast_date), to = ymd(forecast_date) + forecast_horizon, by = "day")


# Fit linear model based on past data: water temperature = m * air temperature + b
fit <- lm(targets_lm$Temp_C_mean ~ targets_lm$air_temperature)
    
print(fit)

coeff <- fit$coefficients

# Use the fitted linear model to forecast water temperature for each ensemble member on each date
for (t in 1:length(forecast_dates)) {
  
  #pull driver ensemble for the relevant date; using all 31 NOAA ensemble members
  temp_driv <- future_weather |> 
    filter(datetime == forecast_dates[t])
  
  
  forecasted_temperature <- coeff[1] + coeff[2] * temp_driv$air_temperature

  # Put all the relevant information into a tibble that we can bind together
  temp_lm_forecast <- tibble(datetime = temp_driv$datetime,
                             site_id = temp_driv$site_id,
                             parameter = temp_driv$parameter,
                             prediction = forecasted_temperature,
                             variable = "Temp_C_mean")
  
  forecast_df <- dplyr::bind_rows(forecast_df, temp_lm_forecast)
  
}

forecast_df  
```

We now have 31 possible forecasts of water temperature at each site and each day. On this plot each line represents one of the possible forecasts and the range of forecasted water temperature is a simple quantification of the uncertainty in our forecast.

Looking at the forecasts we produced:

```{r wq-forecast, echo = F, warning = F}
forecast_df %>% 
  filter(variable == 'Temp_C_mean') %>%
  ggplot(.,aes(x=datetime, y=prediction, group = parameter)) + 
  geom_point(data = filter(targets, depth_m == 1.6), 
             aes(x=as_date(datetime), y=observation, group = 'obs'), colour = 'darkblue') +
  geom_line(alpha = 0.5, aes(colour = 'ensemble member (parameter)')) + 
  facet_wrap(~site_id, scales = 'free_y') +
  scale_x_date(expand = c(0,0), date_labels = "%d %b") +
  labs(y = 'value') +
  geom_vline(aes(linetype = 'reference_datetime', xintercept = Sys.Date()), colour = 'blue', size = 1.5) +
  labs(title = 'site_id', subtitle = 'variable = temperature', caption = 'prediction') + 
  annotate("text", x = forecast_date - days(8), y = 20, label = "past")  +
  annotate("text", x = forecast_date + days(8), y = 20, label = "future")  +
  theme_bw() +
  coord_cartesian(xlim = c(min(forecast_df$datetime) - 10,
                           forecast_date + 30),
                  ylim = c(min(forecast_df$prediction) -1,
                           max(forecast_df$prediction) + 1)) +
  scale_linetype_manual(values = 'dashed', name = '') +
  scale_colour_manual(values = 'darkgrey', name = '') 
```

## Convert to forecast standard for submission

A reminder of the columns needed for an ensemble forecast:

-   `datetime`: forecast timestamp for each time step
-   `reference_datetime`: The start of the forecast
-   `site_id`: code for site
-   `family`: describes how the uncertainty is represented
-   `parameter`: integer value for forecast replicate
-   `variable`: standardized variable name
-   `prediction`: forecasted value
-   `model_id`: model name (no spaces) - including `example` will ensure we don't need to register!

The columns `project_id`, `depth_m`, and `duration` are also needed. For a daily forecast the duration is `P1D`. We produced a water temperature forecast at the focal depth only (1.6 m).

```{r}
# Remember to change the model_id when you make changes to the model structure!
model_id <- 'example_ID'

forecast_df_standard <- forecast_df %>%
  mutate(model_id = model_id,
         reference_datetime = forecast_date,
         family = 'ensemble',
         parameter = as.character(parameter),
         duration = 'P1D', 
         depth_m = 1.6,
         project_id = 'vera4cast') %>%
  select(datetime, reference_datetime, site_id, duration, family, parameter, variable, prediction, depth_m, model_id, project_id)
```

# Submit forecast

Files need to be in the correct format for submission. The forecast organizers have created tools to help aid in the submission process. These tools can be downloaded from Github using `remotes::install_github('LTREB-reservoirs/vera4castHelpers')`. These include functions for submitting, scoring, and reading forecasts:

-   `submit()` - submit the forecast file to the VERA Challenge, where it will be scored
-   `forecast_output_validator()` - check the file is in the correct format to be submitted

```{r eval = T}
# Start by writing the forecast to file
save_here <- 'Forecasts/' # just for helpful organisation
forecast_file <- paste0(save_here, forecast_date, '-', model_id, '.csv')

if (dir.exists(save_here)) {
  write_csv(forecast_df_standard, forecast_file)
} else {
  dir.create(save_here)
  write_csv(forecast_df_standard, forecast_file)
}

```


```{r}
vera4castHelpers::forecast_output_validator(forecast_file = forecast_file)
```
The checks show us that our forecast is valid and we can go ahead and submit it!

```{r eval = FALSE, echo = T}
vera4castHelpers::submit(forecast_file = forecast_file)
```

Is the linear model a reasonable relationship between air temperature and water temperature? Would a non-linear relationship be better? What about using yesterday's air and water temperatures to predict tomorrow? Or including additional parameters? There's a lot of variability in water temperatures unexplained by air temperature alone.

```{r linear-model, echo=F, warning=F, message=FALSE}
ggplot(targets_lm, aes(x=air_temperature, y= Temp_C_mean)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = 'lm', se = F)
```

# TASKS

Possible modifications to the simple linear model:

-   Include additional weather co-variates in the linear model. List them in the `noaa_stage2` and `noaa_stage3` functions before `collect()`.
-   Specify a non-linear relationship.
-   Try forecasting another variable - could you use your water temperature to estimate dissolved oxygen concentration at the surface? To learn more about the other focal variables, see [here](https://www.ltreb-reservoirs.org/vera4cast/targets.html).
-   Include a lag in the predictors.
-   Add another source of uncertainty - what are the errors in the linear model? - Check out [Macrosystems EDDIE module 6](https://github.com/MacrosystemsEDDIE/module6_R)!

Until you start submitting 'real' forecasts you can (should) keep `example` in the model_id. These forecasts are processed and scored but are not retained for longer than 1 month.

# Register your participation

It's really important that once you start submitting forecasts to the Challenge that you register your participation. You will not be able to submit a forecast that is not an example, without first registering the model_id, with associated metadata. You should register [here](https://forms.gle/kg2Vkpho9BoMXSy57).

Read more on the VERA Forecast Challenge website <https://www.ltreb-reservoirs.org/vera4cast/instructions.html>.

# What's next?

More information and some helpful materials about adding additional sources of uncertainty and developing your forecasts can be found on the [VERA website](https://www.ltreb-reservoirs.org/vera4cast/learn-more.html).

Once you're happy with your model, you can follow the instructions in the `forecast_code` directory to start submitting automated forecasts.
